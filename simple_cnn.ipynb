{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1  Leaves Recognition using CNN\n",
    "    We do the machine learning work use CNN method. the trainset We use is a csv file. And there are 192 parameters in the csv file for each leaves. and we will train it with several methods and compare the respectively accuracy with each other and find the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lanwe\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Convolution1D, Dropout,Convolution2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('100 leaves plant species/train0.csv')\n",
    "test = pd.read_csv('100 leaves plant species/test01.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode train and test in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode(train, test):\n",
    "    label_encoder = LabelEncoder().fit(train.species)\n",
    "    labels = label_encoder.transform(train.species)\n",
    "    classes = list(label_encoder.classes_)\n",
    "\n",
    "    train = train.drop(['species', 'id'], axis=1)\n",
    "    test = test.drop('id', axis=1)\n",
    "\n",
    "    return train, labels, test, classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, labels, test, classes = encode(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use standerdscaler to remove the mean and normalize the variance.\n",
    "Split train data into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standardize train features\n",
    "scaler = StandardScaler().fit(train.values)\n",
    "scaled_train = scaler.transform(train.values)\n",
    "\n",
    "# split train data into train and validation\n",
    "sss = StratifiedShuffleSplit(test_size=0.1, random_state=23)\n",
    "for train_index, valid_index in sss.split(scaled_train, labels):\n",
    "    X_train, X_valid = scaled_train[train_index], scaled_train[valid_index]\n",
    "    y_train, y_valid = labels[train_index], labels[valid_index]\n",
    "    \n",
    "\n",
    "nb_features = 64 # number of features per features type (shape, texture, margin)   \n",
    "nb_class = len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape train data\n",
    "X_train_r = np.zeros((len(X_train), nb_features, 3))\n",
    "X_train_r[:, :, 0] = X_train[:, :nb_features]\n",
    "X_train_r[:, :, 1] = X_train[:, nb_features:128]\n",
    "X_train_r[:, :, 2] = X_train[:, 128:]\n",
    "\n",
    "# reshape validation data\n",
    "X_valid_r = np.zeros((len(X_valid), nb_features, 3))\n",
    "X_valid_r[:, :, 0] = X_valid[:, :nb_features]\n",
    "X_valid_r[:, :, 1] = X_valid[:, nb_features:128]\n",
    "X_valid_r[:, :, 2] = X_valid[:, 128:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single convolutional layer\n",
    "\n",
    "    Activation method: relu;\n",
    "    Train method: softmax;\n",
    "    Loss: categorical_crossentropty;\n",
    "    Opimizer: sgd;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lanwe\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(input_shape=(64, 3), filters=512, kernel_size=1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\lanwe\\Anaconda3\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1116 samples, validate on 124 samples\n",
      "Epoch 1/15\n",
      "1116/1116 [==============================] - 54s 48ms/step - loss: 4.4955 - acc: 0.0797 - val_loss: 4.3030 - val_acc: 0.2903\n",
      "Epoch 2/15\n",
      "1116/1116 [==============================] - 52s 47ms/step - loss: 4.1240 - acc: 0.2841 - val_loss: 3.8020 - val_acc: 0.3629\n",
      "Epoch 3/15\n",
      "1116/1116 [==============================] - 53s 47ms/step - loss: 3.4783 - acc: 0.4579 - val_loss: 2.9814 - val_acc: 0.6210\n",
      "Epoch 4/15\n",
      "1116/1116 [==============================] - 52s 47ms/step - loss: 2.4692 - acc: 0.6819 - val_loss: 1.8897 - val_acc: 0.7742\n",
      "Epoch 5/15\n",
      "1116/1116 [==============================] - 52s 47ms/step - loss: 1.4162 - acc: 0.8253 - val_loss: 1.1243 - val_acc: 0.8629\n",
      "Epoch 6/15\n",
      "1116/1116 [==============================] - 52s 47ms/step - loss: 0.7641 - acc: 0.9167 - val_loss: 0.7441 - val_acc: 0.9032\n",
      "Epoch 7/15\n",
      "1116/1116 [==============================] - 54s 48ms/step - loss: 0.4750 - acc: 0.9462 - val_loss: 0.5711 - val_acc: 0.8952\n",
      "Epoch 8/15\n",
      "1116/1116 [==============================] - 52s 47ms/step - loss: 0.3272 - acc: 0.9606 - val_loss: 0.4544 - val_acc: 0.9113\n",
      "Epoch 9/15\n",
      "1116/1116 [==============================] - 52s 47ms/step - loss: 0.2332 - acc: 0.9677 - val_loss: 0.3928 - val_acc: 0.9194\n",
      "Epoch 10/15\n",
      "1116/1116 [==============================] - 52s 47ms/step - loss: 0.1851 - acc: 0.9758 - val_loss: 0.3488 - val_acc: 0.9516\n",
      "Epoch 11/15\n",
      "1116/1116 [==============================] - 52s 47ms/step - loss: 0.1439 - acc: 0.9857 - val_loss: 0.3373 - val_acc: 0.9435\n",
      "Epoch 12/15\n",
      "1116/1116 [==============================] - 52s 47ms/step - loss: 0.1131 - acc: 0.9928 - val_loss: 0.3460 - val_acc: 0.9355\n",
      "Epoch 13/15\n",
      "1116/1116 [==============================] - 52s 47ms/step - loss: 0.0923 - acc: 0.9937 - val_loss: 0.2991 - val_acc: 0.9355\n",
      "Epoch 14/15\n",
      "1116/1116 [==============================] - 53s 48ms/step - loss: 0.0802 - acc: 0.9946 - val_loss: 0.3058 - val_acc: 0.9516\n",
      "Epoch 15/15\n",
      "1116/1116 [==============================] - 53s 47ms/step - loss: 0.0681 - acc: 0.9973 - val_loss: 0.2897 - val_acc: 0.9516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x253f2f4e358>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unfortunately more number of covnolutional layers, filters and filters lenght \n",
    "# don't give better accuracy\n",
    "model = Sequential()\n",
    "model.add(Convolution1D(nb_filter=512, filter_length=1, input_shape=(nb_features, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(nb_class))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, nb_class)\n",
    "y_valid = np_utils.to_categorical(y_valid, nb_class)\n",
    "\n",
    "sgd = SGD(lr=0.01, nesterov=True, decay=1e-6, momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
    "\n",
    "nb_epoch = 15\n",
    "model.fit(X_train_r, y_train, nb_epoch=nb_epoch, validation_data=(X_valid_r, y_valid), batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change train method to sigmoid\n",
    "    Therefore, it is especially used for models where we have to predict the probability as an output.Since probability of anything exists only between the range of 0 and 1, sigmoid is the right choice.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lanwe\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(input_shape=(64, 3), filters=512, kernel_size=1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\lanwe\\Anaconda3\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1116 samples, validate on 124 samples\n",
      "Epoch 1/15\n",
      "1116/1116 [==============================] - 54s 49ms/step - loss: 4.5821 - acc: 0.0323 - val_loss: 4.5418 - val_acc: 0.1855\n",
      "Epoch 2/15\n",
      "1116/1116 [==============================] - 52s 47ms/step - loss: 4.5172 - acc: 0.1577 - val_loss: 4.4757 - val_acc: 0.3387\n",
      "Epoch 3/15\n",
      "1116/1116 [==============================] - 52s 47ms/step - loss: 4.4473 - acc: 0.3065 - val_loss: 4.4015 - val_acc: 0.4274\n",
      "Epoch 4/15\n",
      "1116/1116 [==============================] - 53s 47ms/step - loss: 4.3665 - acc: 0.4274 - val_loss: 4.3148 - val_acc: 0.5161\n",
      "Epoch 5/15\n",
      "1116/1116 [==============================] - 53s 47ms/step - loss: 4.2686 - acc: 0.5197 - val_loss: 4.2056 - val_acc: 0.5726\n",
      "Epoch 6/15\n",
      "1116/1116 [==============================] - 52s 47ms/step - loss: 4.1297 - acc: 0.5923 - val_loss: 4.0350 - val_acc: 0.6210\n",
      "Epoch 7/15\n",
      "1116/1116 [==============================] - 52s 47ms/step - loss: 3.8626 - acc: 0.6631 - val_loss: 3.6246 - val_acc: 0.6855\n",
      "Epoch 8/15\n",
      "1116/1116 [==============================] - 52s 47ms/step - loss: 3.0837 - acc: 0.7258 - val_loss: 2.5138 - val_acc: 0.6613\n",
      "Epoch 9/15\n",
      "1116/1116 [==============================] - 52s 47ms/step - loss: 1.8787 - acc: 0.7195 - val_loss: 1.5403 - val_acc: 0.7177\n",
      "Epoch 10/15\n",
      "1116/1116 [==============================] - 52s 47ms/step - loss: 1.0792 - acc: 0.8065 - val_loss: 0.9715 - val_acc: 0.7903\n",
      "Epoch 11/15\n",
      "1116/1116 [==============================] - 52s 47ms/step - loss: 0.6490 - acc: 0.8835 - val_loss: 0.7104 - val_acc: 0.8387\n",
      "Epoch 12/15\n",
      "1116/1116 [==============================] - 52s 47ms/step - loss: 0.4443 - acc: 0.9176 - val_loss: 0.6546 - val_acc: 0.8710\n",
      "Epoch 13/15\n",
      "1116/1116 [==============================] - 52s 47ms/step - loss: 0.3008 - acc: 0.9471 - val_loss: 0.6229 - val_acc: 0.8468\n",
      "Epoch 14/15\n",
      "1116/1116 [==============================] - 52s 47ms/step - loss: 0.2297 - acc: 0.9534 - val_loss: 0.8060 - val_acc: 0.8226\n",
      "Epoch 15/15\n",
      "1116/1116 [==============================] - 52s 47ms/step - loss: 0.1847 - acc: 0.9659 - val_loss: 0.3910 - val_acc: 0.9113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ccb2735dd8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unfortunately more number of covnolutional layers, filters and filters lenght \n",
    "# don't give better accuracy\n",
    "model = Sequential()\n",
    "model.add(Convolution1D(nb_filter=512, filter_length=1, input_shape=(nb_features, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(nb_class))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, nb_class)\n",
    "y_valid = np_utils.to_categorical(y_valid, nb_class)\n",
    "\n",
    "sgd = SGD(lr=0.01, nesterov=True, decay=1e-6, momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
    "\n",
    "nb_epoch = 15\n",
    "model.fit(X_train_r, y_train, nb_epoch=nb_epoch, validation_data=(X_valid_r, y_valid), batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss method changed to binary_crossentropy\n",
    "    but the loss method is not suitable for our dataset, because the scale and the shape of our dataset\n",
    "    the accuracy computed with the Keras method \"evaluate\" is just plain wrong when using binary_crossentropy with more than 2 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lanwe\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(filters=512, kernel_size=1, input_shape=(64, 3))`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\lanwe\\Anaconda3\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1116 samples, validate on 124 samples\n",
      "Epoch 1/15\n",
      "1116/1116 [==============================] - 64s 57ms/step - loss: 0.0560 - acc: 0.9900 - val_loss: 0.0560 - val_acc: 0.9900\n",
      "Epoch 2/15\n",
      "1116/1116 [==============================] - 71s 63ms/step - loss: 0.0560 - acc: 0.9900 - val_loss: 0.0560 - val_acc: 0.9900\n",
      "Epoch 3/15\n",
      "1116/1116 [==============================] - 70s 63ms/step - loss: 0.0560 - acc: 0.9900 - val_loss: 0.0560 - val_acc: 0.9900\n",
      "Epoch 4/15\n",
      "1116/1116 [==============================] - 71s 63ms/step - loss: 0.0559 - acc: 0.9900 - val_loss: 0.0560 - val_acc: 0.9900\n",
      "Epoch 5/15\n",
      "1116/1116 [==============================] - 72s 64ms/step - loss: 0.0559 - acc: 0.9900 - val_loss: 0.0559 - val_acc: 0.9900\n",
      "Epoch 6/15\n",
      "1116/1116 [==============================] - 74s 67ms/step - loss: 0.0559 - acc: 0.9900 - val_loss: 0.0559 - val_acc: 0.9900\n",
      "Epoch 7/15\n",
      "1116/1116 [==============================] - 71s 64ms/step - loss: 0.0559 - acc: 0.9900 - val_loss: 0.0559 - val_acc: 0.9900\n",
      "Epoch 8/15\n",
      "1116/1116 [==============================] - 73s 66ms/step - loss: 0.0559 - acc: 0.9900 - val_loss: 0.0559 - val_acc: 0.9900\n",
      "Epoch 9/15\n",
      "1116/1116 [==============================] - 70s 63ms/step - loss: 0.0558 - acc: 0.9900 - val_loss: 0.0558 - val_acc: 0.9900\n",
      "Epoch 10/15\n",
      "1116/1116 [==============================] - 60s 54ms/step - loss: 0.0558 - acc: 0.9900 - val_loss: 0.0558 - val_acc: 0.9900\n",
      "Epoch 11/15\n",
      "1116/1116 [==============================] - 55s 49ms/step - loss: 0.0558 - acc: 0.9900 - val_loss: 0.0558 - val_acc: 0.9900\n",
      "Epoch 12/15\n",
      "1116/1116 [==============================] - 55s 49ms/step - loss: 0.0558 - acc: 0.9900 - val_loss: 0.0557 - val_acc: 0.9900\n",
      "Epoch 13/15\n",
      "1116/1116 [==============================] - 55s 49ms/step - loss: 0.0557 - acc: 0.9900 - val_loss: 0.0557 - val_acc: 0.9900\n",
      "Epoch 14/15\n",
      "1116/1116 [==============================] - 55s 49ms/step - loss: 0.0557 - acc: 0.9900 - val_loss: 0.0557 - val_acc: 0.9900\n",
      "Epoch 15/15\n",
      "1116/1116 [==============================] - 55s 49ms/step - loss: 0.0557 - acc: 0.9900 - val_loss: 0.0557 - val_acc: 0.9900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dad7906c50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unfortunately more number of covnolutional layers, filters and filters lenght \n",
    "# don't give better accuracy\n",
    "model = Sequential()\n",
    "model.add(Convolution1D(nb_filter=512, filter_length=1, input_shape=(nb_features, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(nb_class))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, nb_class)\n",
    "y_valid = np_utils.to_categorical(y_valid, nb_class)\n",
    "\n",
    "sgd = SGD(lr=0.01, nesterov=True, decay=1e-6, momentum=0.9)\n",
    "model.compile(loss='binary_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
    "\n",
    "nb_epoch = 15\n",
    "model.fit(X_train_r, y_train, nb_epoch=nb_epoch, validation_data=(X_valid_r, y_valid), batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce epoch from 15 to 8, see  if we can get same accuracy, and the answer is no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lanwe\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(input_shape=(64, 3), filters=512, kernel_size=1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\lanwe\\Anaconda3\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1116 samples, validate on 124 samples\n",
      "Epoch 1/8\n",
      "1116/1116 [==============================] - 56s 50ms/step - loss: 4.5169 - acc: 0.0789 - val_loss: 4.3393 - val_acc: 0.3306\n",
      "Epoch 2/8\n",
      "1116/1116 [==============================] - 54s 49ms/step - loss: 4.1789 - acc: 0.2912 - val_loss: 3.8778 - val_acc: 0.4355\n",
      "Epoch 3/8\n",
      "1116/1116 [==============================] - 54s 49ms/step - loss: 3.5785 - acc: 0.4731 - val_loss: 3.1012 - val_acc: 0.5968\n",
      "Epoch 4/8\n",
      "1116/1116 [==============================] - 54s 49ms/step - loss: 2.6146 - acc: 0.6703 - val_loss: 2.0194 - val_acc: 0.7581\n",
      "Epoch 5/8\n",
      "1116/1116 [==============================] - 55s 49ms/step - loss: 1.5097 - acc: 0.8423 - val_loss: 1.1759 - val_acc: 0.8790\n",
      "Epoch 6/8\n",
      "1116/1116 [==============================] - 54s 49ms/step - loss: 0.8113 - acc: 0.9149 - val_loss: 0.7711 - val_acc: 0.8871\n",
      "Epoch 7/8\n",
      "1116/1116 [==============================] - 54s 49ms/step - loss: 0.4874 - acc: 0.9409 - val_loss: 0.5695 - val_acc: 0.8790\n",
      "Epoch 8/8\n",
      "1116/1116 [==============================] - 55s 50ms/step - loss: 0.3289 - acc: 0.9552 - val_loss: 0.4676 - val_acc: 0.9113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ab0b828d68>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unfortunately more number of covnolutional layers, filters and filters lenght \n",
    "# don't give better accuracy\n",
    "model = Sequential()\n",
    "model.add(Convolution1D(nb_filter=512, filter_length=1, input_shape=(nb_features, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(nb_class))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, nb_class)\n",
    "y_valid = np_utils.to_categorical(y_valid, nb_class)\n",
    "\n",
    "sgd = SGD(lr=0.01, nesterov=True, decay=1e-6, momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
    "\n",
    "nb_epoch = 8\n",
    "model.fit(X_train_r, y_train, nb_epoch=nb_epoch, validation_data=(X_valid_r, y_valid), batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change optimizer from sgd to adam\n",
    "The Adaptive Moment Estimation is essentially RMSprop with momentum term, which USES the first Moment Estimation of the gradient and the second-order Moment Estimation to dynamically adjust the learning rate of each parameter.The advantage of Adam is that after the offset correction, each iteration learning rate has a certain range, which makes the parameter relatively stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lanwe\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(filters=512, kernel_size=1, input_shape=(64, 3))`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\lanwe\\Anaconda3\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1116 samples, validate on 124 samples\n",
      "Epoch 1/15\n",
      "1116/1116 [==============================] - 110s 98ms/step - loss: 2.4553 - acc: 0.4749 - val_loss: 0.9471 - val_acc: 0.7419\n",
      "Epoch 2/15\n",
      "1116/1116 [==============================] - 108s 96ms/step - loss: 0.3486 - acc: 0.9023 - val_loss: 0.5368 - val_acc: 0.8306\n",
      "Epoch 3/15\n",
      "1116/1116 [==============================] - 108s 97ms/step - loss: 0.1140 - acc: 0.9713 - val_loss: 0.5350 - val_acc: 0.8306\n",
      "Epoch 4/15\n",
      "1116/1116 [==============================] - 108s 97ms/step - loss: 0.2570 - acc: 0.9471 - val_loss: 0.6428 - val_acc: 0.8629\n",
      "Epoch 5/15\n",
      "1116/1116 [==============================] - 108s 97ms/step - loss: 0.1240 - acc: 0.9686 - val_loss: 0.5016 - val_acc: 0.8629\n",
      "Epoch 6/15\n",
      "1116/1116 [==============================] - 108s 97ms/step - loss: 0.0777 - acc: 0.9776 - val_loss: 0.6778 - val_acc: 0.8548\n",
      "Epoch 7/15\n",
      "1116/1116 [==============================] - 108s 97ms/step - loss: 0.1558 - acc: 0.9686 - val_loss: 0.5772 - val_acc: 0.8952\n",
      "Epoch 8/15\n",
      "1116/1116 [==============================] - 111s 100ms/step - loss: 0.1189 - acc: 0.9767 - val_loss: 0.4762 - val_acc: 0.9113\n",
      "Epoch 9/15\n",
      "1116/1116 [==============================] - 102s 91ms/step - loss: 0.0526 - acc: 0.9928 - val_loss: 0.6214 - val_acc: 0.8710\n",
      "Epoch 10/15\n",
      "1116/1116 [==============================] - 102s 92ms/step - loss: 0.0902 - acc: 0.9830 - val_loss: 0.5417 - val_acc: 0.9032\n",
      "Epoch 11/15\n",
      "1116/1116 [==============================] - 102s 92ms/step - loss: 0.0891 - acc: 0.9848 - val_loss: 0.4913 - val_acc: 0.8790\n",
      "Epoch 12/15\n",
      "1116/1116 [==============================] - 103s 93ms/step - loss: 0.2661 - acc: 0.9606 - val_loss: 0.9220 - val_acc: 0.8306\n",
      "Epoch 13/15\n",
      "1116/1116 [==============================] - 102s 91ms/step - loss: 0.1558 - acc: 0.9695 - val_loss: 0.6659 - val_acc: 0.8468\n",
      "Epoch 14/15\n",
      "1116/1116 [==============================] - 102s 92ms/step - loss: 0.0568 - acc: 0.9857 - val_loss: 0.4911 - val_acc: 0.9113\n",
      "Epoch 15/15\n",
      "1116/1116 [==============================] - 102s 91ms/step - loss: 0.0452 - acc: 0.9875 - val_loss: 0.7135 - val_acc: 0.8871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21733477eb8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unfortunately more number of covnolutional layers, filters and filters lenght \n",
    "# don't give better accuracy\n",
    "model = Sequential()\n",
    "model.add(Convolution1D(nb_filter=512, filter_length=1, input_shape=(nb_features, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(nb_class))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, nb_class)\n",
    "y_valid = np_utils.to_categorical(y_valid, nb_class)\n",
    "\n",
    "sgd = SGD(lr=0.01, nesterov=True, decay=1e-6, momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "nb_epoch = 15\n",
    "model.fit(X_train_r, y_train, nb_epoch=nb_epoch, validation_data=(X_valid_r, y_valid), batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when we use the epoch 15, softmax , sgd categorical_crossentropy we can get the best accuracy about 95 percent. Although when the loss moehod is Binary_crossentropy,we can get 99 percent accuracy,but it may not suitable for our dataset because we cannot make data binary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    reference: CNN example:https://www.kaggle.com/tobikaggle/nn-through-keras-copied-mod-shuffle\n",
    "\n",
    "    CNN: https://github.com/keras-team/keras/blob/master/examples/imdb_cnn.py\n",
    "\n",
    "    CNN: https://www.kaggle.com/tonypoe/keras-cnn-example?scriptVersionId=589403"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Copyright <2018> <Weiyi Lan YiQun Xu Yang Zong>\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
