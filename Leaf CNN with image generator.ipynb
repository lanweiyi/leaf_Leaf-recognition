{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 Leaf Recognition Using CNN with Image Generator\n",
    "    Train the csv file and the image file at the same time. change the pixel and train method and find the most suitable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lanwe\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\lanwe\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize, rotate, SimilarityTransform, warp\n",
    "from skimage.filters import sobel\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "np.random.seed(1337) # for reproducibility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading the train.csv to find features for each training point\n",
    "train = pd.read_csv('100 leaves plant species/train0.csv', usecols=['id', 'species'])\n",
    "mtrain = train.shape[0]\n",
    "test = pd.read_csv('100 leaves plant species/test01.csv', usecols = [0])\n",
    "mtest = test.shape[0]\n",
    "#print(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize and read images\n",
    "Fill image to same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and resizing images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lanwe\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape: (1240, 64, 64)\n",
      "Test images shape: (357, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "print('Loading and resizing images...')# % len(image_paths))\n",
    "img_rows, img_cols = 64, 64 #96,96 #40, 40\n",
    "output_shape = (img_rows, img_cols)\n",
    "\n",
    "train_images = np.zeros((mtrain, img_rows, img_cols))\n",
    "for i in range(mtrain):\n",
    "    #image = imread('images/'+str(train.id.iloc[i])+'.jpg')\n",
    "    image = imread('100 leaves plant species/image/'+str(train.id.iloc[i])+'.jpg')\n",
    "    rimage = resize(image, output_shape=output_shape)\n",
    "    train_images[i] = sobel(rimage)\n",
    "    \n",
    "test_images = np.zeros((mtest, img_rows, img_cols))\n",
    "for i in range(mtest):\n",
    "    image = imread('100 leaves plant species/image/'+str(test.id.iloc[i])+'.jpg')\n",
    "    rimage = resize(image, output_shape=output_shape)\n",
    "    test_images[i] = sobel(rimage)\n",
    "\n",
    "print('Train images shape: {}'.format(train_images.shape)) # 1240\n",
    "print('Test images shape: {}'.format(test_images.shape)) # 357"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target shape: (1240,)\n",
      "100\n",
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Target\n",
    "le = LabelEncoder()\n",
    "target = le.fit_transform(train.species)\n",
    "print(\"Target shape: {}\".format(target.shape))\n",
    "print(np.unique(target).size)\n",
    "print(target[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigger validation set\n",
    "change the train set as validation set so that the validation set is the biggest one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Xtrain, ytrain shapes ((1240, 64, 64), (1240,))\n",
      "Xval, yval shapes ((1240, 64, 64), (1240,))\n"
     ]
    }
   ],
   "source": [
    "# Create random train and validation sets out of 20% samples\n",
    "#Xtrain, Xval, ytrain, yval = train_test_split(train_images, target, test_size=0.15,\n",
    "#                                           stratify=target, random_state=14) #11)\n",
    "Xtrain, ytrain = train_images, target\n",
    "Xval, yval = Xtrain, ytrain \n",
    "print('\\nXtrain, ytrain shapes ' + str((Xtrain.shape, ytrain.shape)))\n",
    "print('Xval, yval shapes ' + str((Xval.shape, yval.shape)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape data as a 4-dim tensor [number samples, width, height, color channels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshape as 4-dim tensor (Tensorflow backend)\n",
      "(1240, 64, 64, 1) (1240, 64, 64, 1) (357, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Reshape as 4-dim tensor (Tensorflow backend)')\n",
    "Xtrain = Xtrain.reshape(Xtrain.shape[0], img_rows, img_cols, 1) # 792\n",
    "Xval = Xval.reshape(Xval.shape[0], img_rows, img_cols, 1) # 198\n",
    "Xtest = test_images.reshape(test_images.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "print(Xtrain.shape, Xval.shape, Xtest.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image batch generator\n",
    "reduce the occupication of GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imageGenerator(X, y, batch_size):\n",
    "    img_rows, img_cols = X.shape[1], X.shape[2]\n",
    "    resc = 0.02\n",
    "    rot = 5\n",
    "    transl = 0.01*img_rows\n",
    "    while 1: # Infinite loop\n",
    "        batchX = np.zeros((batch_size, img_rows, img_cols, 1))\n",
    "        # batch_size random indices over train images\n",
    "        batch_ids = np.random.choice(X.shape[0], batch_size)\n",
    "        for j in range(batch_ids.shape[0]): # Loop over random images\n",
    "            # Rotate around center\n",
    "            imagej = rotate(X[batch_ids[j]], angle =rot*np.random.randn())\n",
    "            # Rescale and translate\n",
    "            tf = SimilarityTransform(scale = 1 + resc*np.random.randn(1,2)[0],\n",
    "                                translation = transl*np.random.randn(1,2)[0]) \n",
    "            batchX[j] = warp(imagej, tf)\n",
    "        #batchX = np.reshape(batchX, (batch_size,-1)) # Flattened images for FNN\n",
    "        #print(batchX.shape, y[batch_ids].shape)\n",
    "        yield (batchX, y[batch_ids])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train convolutional neural network\n",
      "Model Parameters:\n",
      "Batch size: 32, epochs: 10, samples per epoch: 12384, n classes: 100\n",
      "\n",
      "Training Keras Convolutional Neural Network...\n"
     ]
    }
   ],
   "source": [
    "# Convolutional Neural Network\n",
    "print('Train convolutional neural network')\n",
    "# Parameters\n",
    "# Batch size: number of training examples in one forward/backward pass. \n",
    "# The higher the batch size, the more memory space you'll need\n",
    "batch_size = 32\n",
    "# Epoch: one forward pass and one backward pass of all the training examples\n",
    "nb_epoch = 10\n",
    "n_extension = 10\n",
    "samples_per_epoch = batch_size*(n_extension*Xtrain.shape[0] // batch_size)\n",
    "# number of convolutional filters to use (a hidden layer is segmented into feature maps\n",
    "# where each unit in a feature map looks for the same feature but at different positions of the input image)\n",
    "#nb_filters = 64\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "# Number of classes\n",
    "nb_classes = np.unique(ytrain).size\n",
    "#kernel_size = (5, 5)\n",
    "print('Model Parameters:')\n",
    "print('Batch size: %d, epochs: %d, samples per epoch: %d, n classes: %d' % \n",
    "                                (batch_size, nb_epoch,samples_per_epoch, nb_classes))\n",
    "\n",
    "print('\\nTraining Keras Convolutional Neural Network...')\n",
    "# Convert class vectors to binary class matrices (one-hot encoder)\n",
    "ytrain = np_utils.to_categorical(ytrain, nb_classes)\n",
    "yval = np_utils.to_categorical(yval, nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lanwe\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (5, 5), padding=\"valid\", input_shape=(64, 64, 1...)`\n",
      "  \n",
      "C:\\Users\\lanwe\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (5, 5))`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\lanwe\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "C:\\Users\\lanwe\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., steps_per_epoch=12384, validation_data=(array([[[..., verbose=1, epochs=10)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12384/12384 [==============================] - 1577s 127ms/step - loss: 0.2460 - acc: 0.9261 - val_loss: 0.0027 - val_acc: 0.9992\n",
      "Epoch 2/10\n",
      "12384/12384 [==============================] - 1522s 123ms/step - loss: 0.0507 - acc: 0.9843 - val_loss: 0.0074 - val_acc: 0.9984\n",
      "Epoch 3/10\n",
      "12384/12384 [==============================] - 1509s 122ms/step - loss: 0.0357 - acc: 0.9891 - val_loss: 1.7023e-04 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      "12384/12384 [==============================] - 1509s 122ms/step - loss: 0.0292 - acc: 0.9913 - val_loss: 3.6244e-04 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "12384/12384 [==============================] - 1510s 122ms/step - loss: 0.0257 - acc: 0.9924 - val_loss: 0.0024 - val_acc: 0.9992\n",
      "Epoch 6/10\n",
      "12384/12384 [==============================] - 1513s 122ms/step - loss: 0.0232 - acc: 0.9932 - val_loss: 9.5909e-05 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "12384/12384 [==============================] - 1512s 122ms/step - loss: 0.0217 - acc: 0.9939 - val_loss: 1.9166e-04 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "12384/12384 [==============================] - 1512s 122ms/step - loss: 0.0211 - acc: 0.9943 - val_loss: 0.0020 - val_acc: 0.9992\n",
      "Epoch 9/10\n",
      "12384/12384 [==============================] - 1508s 122ms/step - loss: 0.0206 - acc: 0.9944 - val_loss: 0.0119 - val_acc: 0.9960\n",
      "Epoch 10/10\n",
      "12384/12384 [==============================] - 1509s 122ms/step - loss: 0.0198 - acc: 0.9947 - val_loss: 8.9119e-05 - val_acc: 1.0000\n",
      "Validation loss: 0.00009\n",
      "Validation accuracy: 100.00\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = Sequential()\n",
    "# Add hidden layers\n",
    "# Conv2D layer with 5x5 kernels (local weights) and 32 conv filters \n",
    "# (or feature maps), expects 2d images as inputs\n",
    "model.add(Convolution2D(16, 5, 5,  border_mode='valid', input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Dropout(0.5)) # Regularization method, exclude 50% units\n",
    "# Another conv2D layer\n",
    "model.add(Convolution2D(32, 5, 5))\n",
    "model.add(Activation('relu'))\n",
    "# Pool2D layer, a form of non-linear down-sampling to prevent\n",
    "# overfitting and provide a form of translation invariance\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "#model.add(Dropout(0.25)) # Regularization method, exclude 25% units\n",
    "# Flattenig layer, converts 2D matrix into vectors\n",
    "model.add(Flatten())\n",
    "# Standard fully connected layer with 128 units\n",
    "# model.add(Dense(256))\n",
    "# model.add(Dropout(0.25)) # Regularization method, exclude 25% units\n",
    "# model.add(Activation('relu'))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "# Fit model with generator\n",
    "model.fit_generator(imageGenerator(Xtrain, ytrain, batch_size), \n",
    "                    samples_per_epoch = samples_per_epoch,\n",
    "                    nb_epoch=nb_epoch, verbose=1, validation_data=(Xval, yval))\n",
    "#model.fit(Xtrain, ytrain, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "#          verbose=1, validation_data=(Xval, yval))\n",
    "score = model.evaluate(Xval, yval, verbose=0)\n",
    "print('Validation loss: %0.5f' % score[0])\n",
    "print('Validation accuracy: %0.2f' % (100*score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we found that this one is the best one. When we use the image and the csv file at the same time, our accuracy is almost 1. But we found that the dimension is too high, so the speed of the process is too slow. In that case, we want to use some methods to reduce the dimension and we can do the machine learning at the same time. Then we found 2 methods, PCA and k-means to do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow CNN：https://www.kaggle.com/jiexus/cnn-with-tensorflow/notebook\n",
    "               \n",
    "               https://keras.io/preprocessing/image/\n",
    "               \n",
    "               https://blog.csdn.net/sinat_26917383/article/details/74922230"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Copyright <2018> <Weiyi Lan YiQun Xu Yang Zong>\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
